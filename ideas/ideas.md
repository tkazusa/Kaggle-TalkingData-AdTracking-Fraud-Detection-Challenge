# 問題の理解
- 広告をクリックするのが本物のユーザーか詐欺かを当てる、ダウンロードしたかを当てる？
- 問題：click_idとis_atributed(appをダウンロードしたかどうか？)
- 評価指標：AUC

# Data
- ip: クリックしたipアドレス
- app: アプリのid
- device: デバイスのタイプ
- os: osのバージョン
- click_time: クリックした時間
- channel id: channel id of mobile ad publisher
- attributed_time: もしユーザーが広告をクリックしたあとにアプリをダウンロードしたら、その時刻
- is_attributed: アプリがダウンロードされたかどうか

# データのロード
ひとまずデータをcsvから普通にpd.read_csv()してみる。
trainとtest合わせてcsvだと8.5Gくらい。

# 基本的にpandasだと遅すぎる。
もろもろ試してみるのに小さいデータセット作るか。
全体EDAはBQ、可視化諸々はpandasでできたら理想。
小さいデータ・セットで試して大丈夫かどうかは、時系列で変化が無いか確認をする。

## Some DEA
- TrainとTestの時系列でのデータ数
  - testのclick_timeの数にばらつきがある。
  - だいたいどの時間も300万回程度あるのに、6,7,8,11,15時は数百もしくはゼロ。
  - suplement入れたらどうなるんやろ？
  - 時間に合わせてis_attributedの数の変化もみたい
  
 - 2017/11/6-10っていつや？
  - 11月第二週、月曜から金曜の平日。
  
### targetの確認
trainデータの中の"is_attributed"
- 0: 184447044→全体の0.99752927858900098
- 1: 456846→全体の0.0024707214109989791

Testデータで不自然にサンプル数少ない、6,7,8,12,15時を除いた場合
- 0: 138103894
- 1: 340878→全体の0.0024621948165727773

さらに、前日9日のみ
- 0: 36987418
- 1:    93786→全体の0.0025292059017285413
  
- 頑張って基本的な前処理だけして、あとはtableauでもいい

## Trとtstの間でデータの分布が結構違うかも？
- ヒストグラム重ねて確認したい


## Feature Eng
- https://www.yasuhisay.info/entry/kaggle_avazu_ctr_prediction
